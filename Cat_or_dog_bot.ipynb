{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc98a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import telebot\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.io\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch.nn as nn\n",
    "import base64\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from telebot import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82444695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "        self.conv0_0 = nn.Conv2d(3, 64, 7, stride=2, padding=0)\n",
    "        \n",
    "        self.conv1_0 = nn.Conv2d(64, 128, 3, stride=1, padding=0)\n",
    "        self.norm1_0 = nn.GroupNorm(32, 128)\n",
    "        \n",
    "        self.conv2_0 = nn.Conv2d(128, 128, 3, stride=1, padding=0)\n",
    "        self.norm2_0 = nn.GroupNorm(32, 128)\n",
    "        self.conv2_1 = nn.Conv2d(128, 256, 3, stride=1, padding=0)\n",
    "        self.norm2_1 = nn.GroupNorm(64, 256)\n",
    "        \n",
    "        self.conv3_0 = nn.Conv2d(256, 256, 3, stride=1, padding=0)\n",
    "        self.norm3_0 = nn.GroupNorm(64, 256)\n",
    "\n",
    "        \n",
    "        self.conv4_0 = nn.Conv2d(256, 512, 3, stride=1, padding=0)\n",
    "        \n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear1 = nn.Linear(512, 32)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear2 = nn.Linear(32, 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "\n",
    "        out = self.conv0_0(x)\n",
    "        out = self.act(out)\n",
    "        #out = self.maxpool(out)\n",
    "\n",
    "        out = self.conv1_0(out)\n",
    "        out = self.norm1_0(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.conv2_0(out)\n",
    "        out = self.norm2_0(out)\n",
    "        out = self.act(out)\n",
    "        out = self.conv2_1(out)\n",
    "        out = self.norm2_1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.conv3_0(out)\n",
    "        out = self.norm3_0(out)\n",
    "        out = self.act(out)\n",
    "\n",
    "        out = self.conv4_0(out)\n",
    "        out = self.act(out)\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        out = self.adaptivepool(out)\n",
    "        out = self.flatten(out)\n",
    "        \n",
    "        out = self.linear1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.act(out)\n",
    "        \n",
    "\n",
    "        return out                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b04603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (act): LeakyReLU(negative_slope=0.2)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv0_0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2))\n",
       "  (conv1_0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (norm1_0): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "  (conv2_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (norm2_0): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "  (conv2_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (norm2_1): GroupNorm(64, 256, eps=1e-05, affine=True)\n",
       "  (conv3_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (norm3_0): GroupNorm(64, 256, eps=1e-05, affine=True)\n",
       "  (conv4_0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (adaptivepool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "token = '6002633936:AAG3pw2BpHaL_S3tWLv7RjT3CLJH6rQCcxA'\n",
    "# Загрузка модели\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('net_85,7.pth'))\n",
    "\n",
    "#model = torch.hub.load('pytorch/vision', 'vgg16', pretrained=True)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a9ce257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для классификации изображения\n",
    "def classify_image(image, my_img):\n",
    "    \n",
    "    # Преобразование изображения в тензор PyTorch и нормализация\n",
    "    transform = transforms.Compose(\n",
    "    [transforms.Resize((112, 112)),    # Изменяем размер изображения до 224x224\n",
    "     transforms.ToTensor(),    # Преобразуем изображение в тензор\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "    \n",
    "    image = transform(image).to(device)\n",
    "    image = image.unsqueeze_(0)\n",
    "\n",
    "    # Классификация изображения с помощью модели\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    \n",
    "    predicted_class = torch.argmax(output).item()\n",
    "\n",
    "    probs = F.softmax(output, dim=1)\n",
    "\n",
    "    dog_prob = probs[0][0].item()  # вероятность класса кошки\n",
    "    cat_prob = probs[0][1].item()  # вероятность класса собаки\n",
    "\n",
    "    if predicted_class == 0: \n",
    "        print('      КОШКА %.2f%%' % (cat_prob*100))\n",
    "        my_img.save(\"cat_\" + (str(cat_prob*100)) + \".jpg\")\n",
    "        return 'Я почти уверен, что это котик!'\n",
    "    else: \n",
    "        print('      СОБАКА %.2f%%' % (dog_prob*100))\n",
    "        my_img.save(\"dog_\" + (str(dog_prob*100)) + \".jpg\")\n",
    "        return 'Я почти уверен, что это пёсик!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d1c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_console(img):\n",
    "    \n",
    "    transform = transforms.Resize((112, 112))\n",
    "    img = transform(img)\n",
    "    \n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed30f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание бота\n",
    "bot = telebot.TeleBot(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbbb72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработчик команды /start\n",
    "@bot.message_handler(commands=['start'])\n",
    "def send_welcome(message):\n",
    "    bot.reply_to(message, \"Привет! Я бот, который может отличать собак от кошек. Пришли мне фото своего питомца и я скажу, кто на нем изображен.\\n\\nУчти, что бот реагирует только на изображения.\\n\\nСамые смешные реакции бота (не только на животных) кидай мне в личку :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6199b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработчик изображения\n",
    "@bot.message_handler(content_types=['photo'])\n",
    "def handle_photo(message):\n",
    "\n",
    "    # Загрузка изображения из сообщения\n",
    "    file_info = bot.get_file(message.photo[-1].file_id)\n",
    "    \n",
    "    image_url = 'https://api.telegram.org/file/bot{0}/{1}'.format(token, file_info.file_path)\n",
    "    \n",
    "    with urllib.request.urlopen(image_url) as url:\n",
    "        image_file = BytesIO(url.read())\n",
    "    \n",
    "    image = Image.open(image_file)\n",
    "    \n",
    "    my_img = image\n",
    "    image_console(my_img)\n",
    "    \n",
    "    # Классификация изображения и отправка результата\n",
    "    result = classify_image(image, my_img)\n",
    "\n",
    "    bot.send_message(message.chat.id, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12eac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск бота\n",
    "bot.polling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
